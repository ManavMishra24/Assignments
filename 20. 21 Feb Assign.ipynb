{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f34a21c-60f3-4f17-815d-3daea52ed37e",
   "metadata": {},
   "source": [
    "20 FEB ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e259a8-6380-408d-a0d2-b724cb6264af",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2eb731c-cd2c-49bd-993a-31ed00d9b040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Web scraping refers to the automated process of extracting information from websites using software tools called web scrapers or crawlers. These tools can visit websites, read their content, and extract relevant information such as text, images, and other data.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Web scraping refers to the automated process of extracting information from websites using software tools called web scrapers or crawlers. These tools can visit websites, read their content, and extract relevant information such as text, images, and other data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0dd9fb-9150-47b8-92b6-6d92aaeb3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "Web scraping is used for various purposes, including:\n",
    "    \n",
    "    1. Research\n",
    "    2. Business Intelligence\n",
    "    3. Marketing\n",
    "    \n",
    "Three areas where web scraping is commonly used to get data are:\n",
    "    \n",
    "    1. E-Commerce\n",
    "    2. Social Media\n",
    "    3. Real Estate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e24b42-0a47-4f6b-972a-f972078ced3d",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b57e3-8fec-4d09-b91f-f82dcd694e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. HTML parsing\n",
    "2. Regular Expressions\n",
    "3. Web API\n",
    "4. Headless Browsers\n",
    "5. Scraping Tools (such as BeautifulSoup, Selenium, Scrapy, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52ad8e-349b-4b97-a3b8-a2bd2b186ba8",
   "metadata": {},
   "source": [
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86b7ee9a-716e-4428-a24f-d23431cf15f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beautiful Soup is a Python library used for web scraping purposes. It is designed to parse HTML and XML documents and extract useful information from them. Beautiful Soup provides a simple and efficient way to navigate and search the HTML and XML code of a website, making it easier to extract data.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Beautiful Soup is a Python library used for web scraping purposes. It is designed to parse HTML and XML documents and extract useful information from them. Beautiful Soup provides a simple and efficient way to navigate and search the HTML and XML code of a website, making it easier to extract data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446101fa-0324-460c-a2a9-b3984ed7f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Beautiful Soup is used for various purposes, including:\"\"\"\n",
    "\n",
    "1. Web Scraping\n",
    "2. Data Extraction\n",
    "3. Data Cleaning\n",
    "4. Web Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f28b4a6-22d9-45f7-b376-aeda807f7b29",
   "metadata": {},
   "source": [
    "4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441239a0-fb7f-4555-8c7d-e25ca1138e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Flask is used in this Project as an API Tool to build connection between the Project and Web Scraping Data.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Flask is used in this Project as an API Tool to build connection between the Project and Web Scraping Data.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a6bedd-c4fd-4d4f-b95c-92d2be02e5cc",
   "metadata": {},
   "source": [
    "5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92b4498-b952-49be-a22b-c0616288c622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name of AWS services used in this project are:  1. AWS Elastic Beanstalk  2. AWS CodePipeline'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Name of AWS services used in this project are:  1. AWS Elastic Beanstalk  2. AWS CodePipeline\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f48acbb-5e22-4cb6-a85a-e6c33ae5bd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AWS Elastic Beanstalk is a fully managed service that makes it easy to deploy and scale web applications and services developed with popular languages and frameworks like Java, Python, .NET, PHP, Node.js, Ruby, and Docker. Elastic Beanstalk abstracts away the complexity of infrastructure management, allowing developers to focus on writing code and building applications.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"AWS Elastic Beanstalk is a fully managed service that makes it easy to deploy and scale web applications and services developed with popular languages and frameworks like Java, Python, .NET, PHP, Node.js, Ruby, and Docker. Elastic Beanstalk abstracts away the complexity of infrastructure management, allowing developers to focus on writing code and building applications.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69737131-6b20-49ac-8fe1-b984cd89da25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AWS CodePipeline is a fully managed continuous delivery service that helps developers automate the release process for their applications. CodePipeline enables developers to build, test, and deploy their code changes continuously, making it easier to release new features and updates to users.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"AWS CodePipeline is a fully managed continuous delivery service that helps developers automate the release process for their applications. CodePipeline enables developers to build, test, and deploy their code changes continuously, making it easier to release new features and updates to users.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
